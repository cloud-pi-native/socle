---
- name: Create harbor Namespace
  kubernetes.core.k8s:
    definition:
      kind: Namespace
      metadata:
        name: "{{ dsc.harbor.namespace }}"

- name: CNPG s3 CA (secret)
  when: >
    dsc.global.backup.cnpg.enabled and
    dsc.global.backup.s3.endpointCA.namespace is defined and
    dsc.global.backup.s3.endpointCA.name is defined and
    dsc.global.backup.s3.endpointCA.key is defined
  block:
    - name: Get secret
      kubernetes.core.k8s_info:
        name: "{{ dsc.global.backup.s3.endpointCA.name }}"
        namespace: "{{ dsc.global.backup.s3.endpointCA.namespace }}"
        kind: Secret
      register: cnpg_s3_ca_resource

    - name: Extract key
      ansible.builtin.set_fact:
        cnpg_s3_ca_pem: "{{ cnpg_s3_ca_resource.resources[0].data[dsc.global.backup.s3.endpointCA.key] }}"

    - name: Set cnpg bundle-ca secret
      kubernetes.core.k8s:
        name: "bundle-cnpg-s3"
        namespace: "{{ dsc.harbor.namespace }}"
        kind: Secret
        api_version: v1
        definition:
          data:
            ca.pem: "{{ cnpg_s3_ca_pem }}"

- name: Set cnpg backup secret
  kubernetes.core.k8s:
    name: "{{ dsc.global.backup.s3.credentials.name }}"
    namespace: "{{ dsc.harbor.namespace }}"
    kind: Secret
    api_version: v1
    definition:
      data:
        accessKeyId: "{{ dsc.global.backup.s3.credentials.accessKeyId.value | b64encode }}"
        secretAccessKey: "{{ dsc.global.backup.s3.credentials.secretAccessKey.value | b64encode }}"
  when: dsc.global.backup.cnpg.enabled

- name: Remove cnpg scheduled backup
  kubernetes.core.k8s:
    api_version: v1
    kind: ScheduledBackup
    namespace: "{{ dsc.harbor.namespace }}"
    name: pg-cluster-harbor
    state: absent
  when: not dsc.global.backup.cnpg.enabled

- name: Create PostgreSQL cluster and harbor database
  kubernetes.core.k8s:
    template: "{{ item }}"
  with_items:
    - pg-cluster-harbor.yaml.j2
    - pg-cluster-harbor-backup.yaml.j2
    - pg-cluster-harbor-nodeport.yaml.j2

- name: Wait pg-cluster-harbor-rw endpoint
  kubernetes.core.k8s_info:
    kind: Endpoints
    namespace: "{{ dsc.harbor.namespace }}"
    name: pg-cluster-harbor-rw
  register: endpoint
  until: endpoint.resources[0].subsets[0].addresses[0] is defined
  retries: 30
  delay: 5

- name: Wait job.batch/pg-cluster-harbor-1-initdb to be terminated
  kubernetes.core.k8s_info:
    kind: Job
    api_version: batch/v1
    namespace: "{{ dsc.harbor.namespace }}"
    name: pg-cluster-harbor-1-initdb
  register: job1
  until: job1.resources | length == 0
  retries: 30
  delay: 5

- name: Get pg-cluster-harbor-app secret
  kubernetes.core.k8s_info:
    namespace: "{{ dsc.harbor.namespace }}"
    kind: Secret
    name: pg-cluster-harbor-app
  register: pg_harbor_db_secret

- name: Create service account
  kubernetes.core.k8s:
    definition:
      kind: ServiceAccount
      metadata:
        name: harbor-sa
        namespace: "{{ dsc.harbor.namespace }}"

- name: Harbor crb
  kubernetes.core.k8s:
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        creationTimestamp:
        name: system:openshift:scc:privileged-harbor
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:openshift:scc:privileged
      subjects:
        - kind: ServiceAccount
          namespace: "{{ dsc.harbor.namespace }}"
          name: harbor-sa

- name: Add helm repo
  kubernetes.core.helm_repository:
    name: harbor
    repo_url: "{{ dsc.harbor.helmRepoUrl }}"
    force_update: true

- name: Set path fact
  ansible.builtin.set_fact:
    path: "{{ role_path + '/templates/values' }}"

- name: Compute Harbor Helm values
  ansible.builtin.include_role:
    name: combine
  vars:
    combine_path: "{{ path }}"
    combine_user_values: "{{ dsc.harbor['values'] }}"
    combine_dest_var: "harbor_values"

- name: Deploy helm
  kubernetes.core.helm:
    name: harbor
    chart_ref: harbor/harbor
    chart_version: "{{ dsc.harbor.chartVersion }}"
    release_namespace: "{{ dsc.harbor.namespace }}"
    values: "{{ harbor_values }}"

- name: Update inventory
  kubernetes.core.k8s:
    kind: Secret
    name: dso-config
    namespace: "{{ dsc.console.namespace }}"
    state: patched
    definition:
      data:
        HARBOR_ADMIN_PASSWORD: "{{ dsc.harbor.adminPassword | b64encode }}"

- name: Wait harbor-core endpoint
  kubernetes.core.k8s_info:
    kind: Endpoints
    namespace: "{{ dsc.harbor.namespace }}"
    name: harbor-core
  register: endpoint
  until: endpoint.resources[0].subsets[0].addresses[0] is defined
  retries: 30
  delay: 5

- name: Get harbor config
  ansible.builtin.uri:
    validate_certs: "{{ dsc.exposedCA.type == 'none' }}"
    url: https://{{ harbor_domain }}/api/v2.0/configurations
    password: "{{ dsc.harbor.adminPassword }}"
    user: admin
    force_basic_auth: true
    body_format: json
    status_code: [200, 503]
  until: get_harbor_config.status != 503
  register: get_harbor_config
  retries: 15

- name: Get harbor client secret
  kubernetes.core.k8s_info:
    kind: Secret
    namespace: "{{ dsc.keycloak.namespace }}"
    name: keycloak-client-secret-harbor-client
  register: harbor_secret
  failed_when: harbor_secret.resources | length == 0

- name: Set Harbor config
  ansible.builtin.set_fact:
    harbor_config:
      auth_mode: oidc_auth
      notification_enable: true
      oidc_admin_group: /admin
      oidc_auto_onboard: true
      oidc_client_id: "{{ harbor_secret.resources[0].data.CLIENT_ID | b64decode }}"
      oidc_endpoint: https://{{ keycloak_domain }}/realms/dso
      oidc_extra_redirect_parms: "{}"
      oidc_group_filter: ""
      oidc_groups_claim: groups
      oidc_name: keycloak
      oidc_scope: openid,generic
      oidc_user_claim: email
      oidc_verify_cert: "{{ dsc.exposedCA.type == 'none' }}"
      project_creation_restriction: adminonly
      quota_per_project_enable: true
      read_only: false
      robot_name_prefix: robot$
      robot_token_duration: 30
      self_registration: false

- name: Assert element
  ansible.builtin.assert:
    that:
      - harbor_config[item] == get_harbor_config.json[item].value
    quiet: true
  with_items:
    - "{{ harbor_config | list }}"
  ignore_errors: true
  register: check_config

- name: PUT harbor config
  ansible.builtin.uri:
    validate_certs: "{{ dsc.exposedCA.type == 'none' }}"
    method: PUT
    url: https://{{ harbor_domain }}/api/v2.0/configurations
    password: "{{ dsc.harbor.adminPassword }}"
    user: admin
    force_basic_auth: true
    body_format: json
    body: "{{ harbor_config | combine({'oidc_client_secret': harbor_secret.resources[0].data.CLIENT_SECRET | b64decode}) }}"
  when: check_config.failed is defined and check_config.failed
  changed_when: true

- name: Get trivy schedule scan config
  ansible.builtin.uri:
    validate_certs: "{{ dsc.exposedCA.type == 'none' }}"
    url: https://{{ harbor_domain }}/api/v2.0/system/scanAll/schedule
    password: "{{ dsc.harbor.adminPassword }}"
    user: admin
    force_basic_auth: true
    body_format: json
    status_code: [200, 503]
  until: get_trivy_schedule_config.status != 503
  register: get_trivy_schedule_config

- name: Wait harbor-jobservice endpoint
  kubernetes.core.k8s_info:
    kind: Endpoints
    namespace: "{{ dsc.harbor.namespace }}"
    name: harbor-jobservice
  register: endpoint
  until: endpoint.resources[0].subsets[0].addresses[0] is defined
  retries: 30
  delay: 5

- name: Enable daily trivy scans
  ansible.builtin.uri:
    validate_certs: "{{ dsc.exposedCA.type == 'none' }}"
    method: POST
    url: https://{{ harbor_domain }}/api/v2.0/system/scanAll/schedule
    password: "{{ dsc.harbor.adminPassword }}"
    user: admin
    force_basic_auth: true
    body_format: json
    status_code: [201]
    body:
      "schedule":
        "type": "Daily"
        "cron": "0 0 0 * * *"
  when: get_trivy_schedule_config.json is undefined

- name: Activate proxy cache
  when: dsc.harbor.proxyCache is defined
  block:
    - name: Enable proxy cache for another registry loop
      ansible.builtin.include_tasks:
        file: create_proxy_cache.yaml
      loop: "{{ dsc.harbor.proxyCache }}"
      loop_control:
        loop_var: proxy_cache
        label: "{{ proxy_cache.name }}"

- name: Set alerting rules
  when: dsc.global.alerting.enabled
  kubernetes.core.k8s:
    template: prometheusrule.yml.j2

- name: Patch serviceMonitors
  when: >
    dsc.global.metrics.enabled and
    dsc.global.metrics.additionalLabels is defined
  block:
    - name: Get serviceMonitors
      kubernetes.core.k8s_info:
        api_version: monitoring.coreos.com/v1
        kind: ServiceMonitor
        namespace: "{{ dsc.harbor.namespace }}"
      register: service_monitors

    - name: Get service_monitors names
      ansible.builtin.set_fact:
        service_monitors_names: "{{ service_monitors.resources | map(attribute='metadata.name') }}"

    - name: Patch serviceMonitors
      kubernetes.core.k8s:
        kind: ServiceMonitor
        namespace: "{{ dsc.harbor.namespace }}"
        state: patched
        name: "{{ item }}"
        definition:
          metadata:
            labels:
              "{{ dsc.global.metrics.additionalLabels }}"
      loop: "{{ service_monitors_names }}"

- name: Patch podMonitors
  when: >
    dsc.global.metrics.enabled and
    dsc.global.metrics.additionalLabels is defined
  block:
    - name: Get podMonitors
      kubernetes.core.k8s_info:
        api_version: monitoring.coreos.com/v1
        kind: PodMonitor
        namespace: "{{ dsc.harbor.namespace }}"
      register: pod_monitors

    - name: Get pod_monitors names
      ansible.builtin.set_fact:
        pod_monitors_names: "{{ pod_monitors.resources | map(attribute='metadata.name') }}"

    - name: Patch podMonitors
      kubernetes.core.k8s:
        kind: PodMonitor
        namespace: "{{ dsc.harbor.namespace }}"
        state: patched
        name: "{{ item }}"
        definition:
          metadata:
            labels:
              "{{ dsc.global.metrics.additionalLabels }}"
      loop: "{{ pod_monitors_names }}"
